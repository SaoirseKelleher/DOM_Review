---
title: "Twenty years of dynamic occupancy models: a review of applications and a look towards the future"
date: today

authors:
  - name: Saoirse Kelleher
    affiliation: University of Melbourne
    email: saoirse.kelleher@student.unimelb.edu.au
    orcid: 0000-0002-4614-5753
    corresponding: true
  - name: Natalie Briscoe
    affiliation: University of Melbourne
  - name: Gurutzeta Guillera-Arroita
    affiliation: Pyrenean Institute of Ecology, Spanish National Research Council
  - name: Jane Elith
    affiliation: University of Melbourne
    
abstract: | 
  Describing patterns of species occupancy across landscapes and throughout time is a fundamental aspect of much ecological research. The dynamic multi-season occupancy model is an important tool for analysing wildlife occurence data -- by explicitly estimating colonisation and extinction probabilities while accounting for imperfect detection, it strikes a favourable balance between realism and feasibility. These models can be used in similar ways to more conventional species distribution models, which can struggle to deal with imperfect detection and non-equilibrium populations.
  
  We present a review of applications of the dynamic occupancy model in the twenty years since its initial publication. Our findings indicate that this model demonstrates exceptional flexibility with suitability to address a wide range of ecological questions, and that it may have  broader potential than commonly thought. We also note that practices in fitting dynamic occupancy models are highly variable, and that the existing literature lacks clear answers for best practices. This contrasts with the strong focus on modelling practices in the species distribution model literature, which we suggest may be a valuable resource for improving how authors implement dynamic occupancy models.
---

# Introduction

Ecologists have long sought to describe the processes by which species are distributed across landscapes and throughout time [@humboldt1849], and an understanding of where a species exists, which factors lead to its presence, and how its distribution may change is increasingly important in a dynamic and changing world. Descriptions of how widespread a species is and where it occurs are the foundation of monitoring programs assessing conservation status, and identifying potential drivers of occurrence can help inform potential management actions. Robust knowledge of the occupancy patterns of a species also helps us to predict where a species is most likely to occur, both under present conditions and hypothetical future scenarios.

The inherent value in understanding these patterns of occurrence has led to the development of several techniques for modelling occupancy. However, several factors can make occupancy challenging to describe quantitatively. For instance, when conducting surveys it is often impossible to determine whether a location is truly unoccupied or whether the species occurs but was not detected by the observer. This 'imperfect detection' is a near-ubiquitous characteristic of wildlife presence/absence data and is known to bias estimates of occupancy in conventional SDMs [@lahoz-monfort2014; @gu2004]. Despite this, many popular models make no adjustments for this source of bias [@kellner2014]. Another challenge lies in modelling occupancy under non-equilibrium conditions where a species' distribution or relationship to its environment is in flux, as occurs during range shifts or biological invasions. Conventional correlative SDMs often perform poorly in these scenarios [@dormann2007; @elith2010], a noteworthy challenge given the increased frequency of these events in the Anthopocene [@bertelsmeier2013; @lenoir2015].

Occupancy models, first introduced in @mackenzie2002, offer an alternative framework for modelling occurrence while accounting for these challenges. By using repeat visits to each site, static occupancy models explicitly describe the observation process and account for imperfect detection to correct for bias in estimates of site occupancy. @mackenzie2003 extended this model to account for changes in occupancy across time periods by explicitly describing processes of colonisation and extinction, relaxing the assumption of equilibrium present in other models of species occurrence. This dynamic occupancy model (DOM) is well-suited to address many research questions in ecology, offering a balance between achievable input data requirements and the complexity necessary to describe intricate natural systems.

This review aims to provide an overview of dynamic occupancy models, their uses, and the ways that they are implemented. Following an introduction to the model form and assumptions, we present a systematic review exploring how authors have used the DOM in the two decades since their development, with emphasis on how they collected data, selected covariates, and evaluated their models. Based on these results we highlight the DOMs flexibility as a tool for understanding occupancy, examine how authors have approached the modelling process, and outline key priorities for future research involving this important model class.

## Dynamic occupancy model form and assumptions

Dynamic occupancy models unite two processes: the ecological process of site occupancy describing the presence or absence of a species at a site at any point in time, and the observational process of detection describing whether a species is observed given that a site is occupied (@fig-modelform). Under this parameterisation, sites exist in either occupied or unoccupied states. In the first step-step, occupancy state at each site is determined by the probability of initial occupancy.In subsequent time steps occupancy state is described as a Markovian process where occupancy is predicated on the site's state in the prior time-step and the probabilities of colonisation and extinction. The observation component of the DOM accounts for imperfect detection - at occupied sites, the detection probability describes whether or not the species is observed during a survey. Under the DOM's standard parameterisation, it is assumed that false-positive detections never occur at unoccupied sites.

![The dynamic occupancy model as described by @mackenzie2003. In the ecological process submodel, the occupancy state of any given site is determined by the *initial occupancy* parameter. In subsequent time-steps, unoccupied sites may become occupied according to the *colonisation probability* and occupied sites may become unoccupied according to the *extinction probability*. The observational process submodel accounts for imperfect detection: during a survey at occupied site, the species may be detected or not according to the *detection probability*. At sites which are truly unoccupied, is it assumed that the species is never detected.](Figures/ModelForm.png){#fig-modelform}

To disentangle the ecological and observational processes the DOM requires a hierarchical sampling design as depicted in @fig-surveys. Under this design, observations at a site occur during distinct, time-bound seasons within which sites are considered closed to changes in occupancy. In each season multiple observations are conducted, permitting estimation of the probability of detection conditional on occupancy. Most frequently these repeat observations are collected by revisiting the site on separate occasions, although they can also be attained by alternative means: examples include conducting surveys at multiple locations within a site, using multiple observers during a survey, or recording the time elapsed until a detection is recorded [@mackenzie2005].

![The sampling design of the standard dynamic occupancy model. During seasons, also called primary occasions, sites are considered closed to changes in true occupancy state; occupancy state may only change between seasons. Within each season, multiple observations ('secondary occasions') are conducted to record the observed presence or absence of the species at each site. These multiple observations may be recorded in many ways: sites can be revisited multiple times within a season, surveys can be conducted at multiple points within a larger site, multiple observers can conduct surveys contemporaneously, or the time elapsed prior to a detection occurring can be recorded. It is not necessary for the same number of observations to occur in each year or each site, allowing for greater flexibility in data inputs.](Figures/SurveyDesign.png){#fig-surveys fig-align="center"}

The descriptions above are based on the original form of the dynamic occupancy model as prescribed in @mackenzie2003. Numerous model extensions and alternative formulations are also available, including implementations accounting for false positives [@royle2006; @miller2011; @miller2015], multiple states beyond occupied and unoccupied [@nichols2007], and jointly estimated multi-species models[@dorazio2010]. For a comprehensive discussion of the most common extensions and their applications see @bailey2014, as well as @devarajan2020 for a review of multi-species occupancy models.

Dynamic occupancy models make a small number of assumptions with important implications:

I.  **False positive detections do not occur**. While this assumption can be safely met in many studies, it is not necessarily guaranteed when working with more cryptic species or less reliable survey methods. @mcclintock2010 and @miller2015 comment on the bias induced when false positives occur and are not accounted for, highlighting the need for authors to consider how certain their detections truly are. Significantly, even genuine detections of a species can be considered 'false positives' when they do not represent the intended definition of occupancy, such as detections of transient individuals when the intent is to estimate breeding occupancy [@berigan2019]. Where this assumption can not reasonably met, aforementioned extensions designed to account for false positive error should be considered.

II. **Sites are closed to occupancy between seasons.** This requirement, best known as the 'closure assumption,' has also been subject to considerable discussion around the bias which is introduced when it is violated [@rota2009; @otto2013]. Closure is dependent not only on the life history of the species, but also on the definition of occupancy used by researchers — short seasons may represent dynamics more representative of species 'use,' and @valente2017 discuss the difficultly in distinguishing between temporary emigration and local extinction. Model extensions to relax the closure assumption have been developed, including @kendall2013's approach using staggered arrival and departure periods between sites. A more pertinent approach for most studies, however, is careful consideration of ecologically relevant seasons corresponding to an appropriate definition of occupancy.

III. **Heterogeneity in occupancy and detection is accounted for.** As with any approach for modelling species distributions, it is assumed that DOMs appropriately capture variation in occupancy patterns and species detectability across the study system. Generally, this is achieved by allowing model parameters to vary with respect to covariates representing environmental factors which may be expected to influence these characteristics. No model will fully account for the complexity inherent in patterns of species occupancy; however, failure to capture key drivers can introduce bias. Compared to the first two assumptions, this aspect of DOMs has been less thoroughly discussed and comparatively little is known how this latent heterogeneity can influence model estimates.

## Building dynamic occupancy models

A key aim of this review is to investigate how authors have approached the steps of the modelling building process, and how these practices have changed since the introduction of these models 20 years ago. The process of fitting DOMs requires decisions by model builders at several key points with meaningful implications for how outputs should be interpreted. This process begins with the project's inception and plans for data collection. The definition of occupancy is contingent on

Authors must also consider the temporal aspect of occupancy by defining primary and secondary occasions. In many cases, this is a simple decision driven by data collection - take a typical bird survey program, where sites may be visited on a few occasions in the breeding season of each year; years and individual visits within years will generally be used as primary and secondary occasions, respectively. However, this choice may not be as clear with other data collection methods. Citizen science programs, camera traps, acoustic monitors can all yield somewhat continuous data which must be arbitrarily segregated into primary and secondary occasions. In this context, it is important to consider both the temporal scale of interest for occupancy and whether or not closure can reasonably be assumed between primary occasions.

Once data has been coerced into a suitable structure for fitting DOMs, modellers must also consider which environmental factors to incorporate into the model, as well as how to incorporate them. These factors will vary considerably by study, but should generally be plausible drivers of variation in either occupancy dynamics or survey observability. Determining which candidate covariates should be included in a final model for drawing inference will generally involve some form of model selection. Covariate selection can be particularly challenging for DOMs relative to other models like SDMs due to their increased complexity. Consider a model with 6 candidate covariates, each of which can be included in any parameter. The number of permutations of this model is given as (2^n^)^p^, where n is the number of candidate covariates and p the number of parameters. A simple single-parameter SDM would have 64 possible formulations, whereas a typical 4-parameter DOM would have over 16 million candidate models given the same covariate pool. For many studies, this precludes exhaustive comparisons of candidate models and demands some form of simplified model selection protocol [@doherty2012]. Multi-model inference is also a common strategy with DOMs, allowing for uncertainty in the difference in fit by averaging estimates from across competing models [@burnham2004].

Several computational tools exist for implementing the DOM and related models. Widely-cited frequentist options include the R package 'unmarked' and the GUI-based programs PRESENCE and MARK. Bayesian DOMs can be written in programs such as JAGS, BUGS, or STAN and fit via R packages such as rJAGS or brms*.* The recently developed R package 'ubms' offers a straightforward Bayesian implementation through an interface similar to *unmarked,* without requiring writing the DOM from scratch.

Upon selecting a final model, authors may evaluate model performance by different methods dependent on the objectives of their studies. While no dedicated goodness-of-fit test exists for DOMs, a version is available for single-season models [@mackenzie2004] which has been extended to multiple seasons; functions are available in *unmarked* and *aicCmodavg.* Another possibility for assessing model fit and predictive ability is via validation. As true occupancy state is generally not known for DOM data, the typical response variable is the observed occupancy state.

# Systematic review methods

To assess how DOMs have been applied in the years since their introduction, we gathered a representative sample of articles fitting them to field ecological data. A pool of candidate articles was generated using two queries on Web of Science. The first included all articles from 2004-2023 citing @mackenzie2003. The second query searched articles matching "dynamic occupancy model\*", "multi-season occupancy model\*", and "occupancy dynamic\*" in any field, articles with each of "occupancy", "colonization", "extinction/persistence", and "detection" in any field, and articles with the term "occupancy" near "dynamic".

As we were interested in how DOMs use has changed through time, we divided articles across five four-year strata: 2004-2007, 2008-2011, 2012-2015, 2016-2019, and 2020-2024. From each of these strata we randomly selected 20 articles for inclusions in the review; articles which did not meet inclusion criteria were replaced from within their own strata.

Our review is focused on applications of the dynamic, multi-season occupancy model of @mackenzie2003 and its extensions. To reflect this, we included articles which fit a model meeting the following criteria:

I.  Uses non-simulated, field-collected presence-absence data.

II. Describes multiple sites which can exist in at least two states including *occupied* and *unoccupied.*

III. Has multiple seasons, between which sites may change states conditional on the prior season's occupancy state and transition probabilities such as colonisation and extinction.

IV. Contains at least one parameter describing the detection process.

For each article we recorded key details on authorship, research objectives, study taxa and system, survey methods, and modelling approach. To assess patterns of authorship, the location of each article's first author's primary affiliation was recorded. *All* affiliations for all authors were classified into one of four categories: academic institutions, governmental organisations and institutes, non-governmental organisations, and private sector companies.

We recorded details on the type of taxa (bird, mammal, etc.) modelled in each article, and how multiple species were modelled where applicable. Taxa were denoted as threatened either when they are listed on the IUCN Red List of Species or when authors otherwise indicate that they are threatened. This deference to authors' representation of conservation status was made to account for sub-species which lack listings or species which are of more local concern. Study locality and size was documented; the size of the study area being defined as the intended area of inference containing all sites, recorded as an order of magnitude to partially account for uncertainty in reporting.

To examine the reasons why authors used DOMs, we allocated each article to one or more category of objective based on the study's stated aims. The possible categories were *Estimating parameters*, where authors express interest in estimates of site occupancy, colonisation, extinction, or detection probabilities; *Testing hypotheses*, where authors explore specific predefined relationships between covariates and model parameters; *Identifying drivers*, where authors attempt to find which covariates influence model parameters; *Generating predictions*, where authors estimate model parameters either for unsurveyed sites or under possible future conditions; and *Methods development*, where authors introduce, test, or demonstrate aspects of dynamic occupancy models.

Particular emphasis was placed on describing how authors conducted their modelling from covariate selection through model evaluation. We recorded all covariates considered in each study, regardless of whether they were or were not included in final models. Key traits of each covariate were recorded including their general category, whether they were directly observed or remotely sensed, whether they were static or varied between seasons, and how they were represented in the model (as a linear term, a polynomial term, or as part of an interaction with another covariate). Model selection procedures were sorted into non-exclusive categories including *A priori*, where only one model was considered; *candidate suite*, where a predefined set of models was considered; *procedural*, where covariates were selected parameter-by-parameter; *exhaustive*, where all possible model combinations were fit; *simple precursors*, where selection was preceded by another simpler model implementation; and *other*. Model evaluation was similarly categorised - options in this case included *goodness of fit*, where absolute metrics of fit were used; and *out-of-sample validation* and *in-sample-validation*, where predictive performance was evaluated using in-sample or out-of-sample data respectively. For the full spreadsheet of data collected and further details on categorisation, see **Appendix I.**

A total of 84 articles were included in this review. Based on the acceptance rate from the secondary sample, an estimated 448 of the 1066 articles in our sample would have met inclusion criteria (@fig-coverage).

![Estimated coverage of articles included in this review, based on the secondary sample's rate of inclusion for each strata.](Figures/CoveragePlot.jpeg){#fig-coverage}

# Applications of DOMs

Dynamic occupancy models are considerably flexible in many ways: they may used to achieve several different objectives, fit to presence-absence data from a variety of sources, and applied to studies at a wide range of spatial and temporal scales. Study locations included in our sample are globally distributed [@fig-StudyDetails A] and span a diverse range of ecosystems. Notably, these study areas vary considerably in size — the smallest study locality included in our sample studied insect occurrence in a rainforest plot smaller than one square kilometre [@basset2023], while the largest analysis modelled avian range shifts across the entire eastern half of the United States [@clement2019].

![A) Study areas: Data for a majority of studies were collected from study locations in the United States. The size of study areas was log-normally distributed, with the median study area falling between 1000 and 10000 square kilometres. \n B) Study taxa: Most species modelled in our sample were terrestrial vertebrates including birds, mammals, or herptiles. 50 articles fit models to only a single taxa, 26 fit independent models to multiple taxa, and 8 fit multi-species models with explicit interactions between taxa. \n C) Survey methods: Approaches to data collected were varied and included conventional surveys like point counts and transects as well as more modern methods like camera traps and acoustic monitors. 10 articles incorporated data from citizen science projects. Project scale was also variable, with the median study running for 3.25 years and covering 98 sites.](Figures/ReviewBox.png){#fig-StudyDetails}

### Focal systems

Although studies were conducted in 21 countries and on all continents except for Antarctica, the majority of reviewed articles used data collected in the United States of America. This strong geographic trend starkly contrasts with SDMs far more international reach; @araújo2019's review of SDM applications found that no more than 20% of studies came from any single continent. The reasons behind this disparity are unclear, but a possible explanation could relate to the DOM's roots in the mark-recapture literature and a history of publication in American journals. These differences in where users conduct their research may also contribute to the seemingly limited overlap between these models' respective bodies of literature.

DOMs have more rarely been applied to non-animal organisms, perhaps due to a reduced emphasis on imperfect detection outside of the wildlife modelling community. However, there are exceptions — @belinchón2017 fits a DOM to lichen data, and @cook2022 uses them to model the spread of chronic wasting disease. The latter's application to disease dynamics is not unique, and DOMs have been a reasonable choice for modelling disease dynamics. @mores2020 and @padilla-torres2013 have each used DOMs to model mosquito dynamics due to their importance as a human disease vector, and @bailey2014 discusses the feasibility of applying the DOM to study the spread of chytrid fungus in amphibian habitat.

Differences in use between SDMs and DOMs are also evident in the species targeted for modelling. Where SDMs show broader coverage of plants, invertebrates, and aquatic species [@araújo2019], 93% of studies in our sample of DOMs modelled terrestrial vertebrate fauna with @belinchón2017's study on lichen the sole non-animal taxa representative. These differences are most easily explained by the DOM's emphasis on imperfect detection, a concern which is less prioritised (though not non-existent [@chen2013]) in studies on non-mobile species like plants. We find DOMs have been frequently used to model threatened taxa (32% of studies) and invasive species (11% of studies), taxa for which they may be expected to excel due to their more explicit handling of changes in occupancy. One group for which DOMs have only rarely been used is aquatic species, as in @fisher2014's application to invasive salmon or @falke2012's model on Great Plains stream fishes.

While most articles focus on a single taxa, 40% of the studies in our sample fit models to more than one taxa ('taxa' defined here as one or more species modelled as one). Of these, 75% fit independent DOMs to multiple species, and 25% fit explicitly multi-species implementations. These multi-species models varied in structure: some use species-specific effects to describe metapopulations by including hundreds of species in a single model [@dorazio2010; @hendershot2020], while others fit models which explicly account for species interactions and estimate conditional occupancy, colonisation, extinction, and detection [@lesmeister2015; @fidino2019]. While they did not fit multi-species models, several other authors fit large numbers of independent models to different species [@peach2019; @otto2012]. Working with large numbers of taxa does raise additional questions, as the level of complexity which can realistically be applied to each individual taxa is likely to be reduced for practicality's sake. With multi-species community frameworks, environmental covariates must be relatively general; and when fitting large numbers of independent models covariate selection processes are likely to be more restricted due to computational limitations.

### Data collection and inputs

DOMs show exceptional diversity in the scales at which they can be implemented. The smallest study area in our sample was less than one kilometre squared, and the largest over one million. Study duration shows similar variation — data collection ran for for less than a month in the shortest study, and for 40 years in the longest, with a median duration of 3.25 years. This reiterates the flexibility of dynamic occupancy models, with explorations of hyper-local patterns of occupancy and analyses of continental-scale distribution using the same underlying model structure. The detection data collected from these surveys came from a variety of detection methods: 69% of articles used human observations, 20% conducted live trapping, 12% used camera traps, and 1% used bioacoustic monitors (@fig-StudyDetails).

The flexibility of DOM inputs data allows for creative uses of detection data from a range of sources. @marescot2020 models a relationship between wildlife and human poachers, using ranger-reported signs of poacher activity to create detection histories. In a rare example of a DOM applied to a marine species, @pendleton2022 uses aerial transects broken up into grid cells to study the occupancy dynamics of whales in the Northeastern United States.

Notably, many reviewed articles use data which was not originally collected in a robust design framework for occupancy modelling. In these articles, authors manipulated their data into a hierarchical format post-hoc using a variety of methods. Some defined primary seasons as a discrete time interval, treating all surveys occurring within the season as secondary occasions. Others defined sites as larger grid cells, treating any survey falling within the grid as a spatial replicate. These manipulations permit authors to use data which far predate the DOM, with one study using surveys from as far back as 1908 to model century-long changes in occupancy [@riddell2021].

Additionally, not all articles rely on a single source of detection data - some integrate multiple sources of data to maximise sample size, combining data from camera traps, sign surveys, and citizen science reports. These integrated detection method models do require additional care in estimating detection probability, which is generally expected to vary based on observation method; however, this can be reasonably achieved by including survey method as a covariate on detection probability [@warrier2020; @pitman2017]. A special case exists when different detection methods are used where one has the potential for false positive detections; e.g., where less-certain citizen science detections are combined with certain detections from field surveys. In this context, the certain detections are used to help account for false-positive detection probability, as in @miller2011's study integrating GPS collars and hunter reports to estimate wolf occupancy in Montana.

It is important to note that the data input requirements for dynamic occupancy models are not as arduous as may be commonly perceived. While it *is* necessary to record multiple observations at individual sites, this does not necessarily require that data be collected according to a strict, preconceived sampling scheme. Post-hoc manipulation of other data such as long-term citizen monitoring programs [@zuckerberg2011; @peach2019], disparate agency modelling programs [@mcgowan2020], or camera trapping data [@davis2018] is feasible with careful consideration. In one example, @riddell2021 used data from as long ago as 1908 by treating grid cells as sites and counting historical surveys within each cell as repeat observations. In a similar vein, all detection data does not necessarily need to come from the same source — detections from multiple methods, with associated variation in detection probabilities, may be incorporated within a single model

Such broadness and flexibility in data inputs is not amenable to a one-size-fits-all definition of occupancy. Authors must carefully consider precisely what they are modelling and address questions on the 'scale' represented by their model [@chave2013]. Drivers of occupancy may differ depending on whether a site is represented by a single point on the landscape or as a grid cell, with the former likely to depend on more local, small scale factors rather than landscape-level trends [@stevens2019]. This is also true for the *temporal* scale of occupancy: whether a site is occupied within a week or within a year is a non-arbitrary distinction representing vastly different conceptions of occupancy. This discussion is particularly pertinent in cases where the selection of season length *is* to some extent arbitrary, as with camera-trap or bioacoustic data where continuous recordings can be broken down into distinct 'seasons' of any length. DOMs are well suited to these data types [@balantic2019], and the proliferation of autonomous survey techniques provides novel opportunities for analysis that is simply not possible with human-collected data. For example, @kleiven2020 and @mölle2022 divide their camera trap records into seasons of just a few days. While this provides exciting insights of occupancy at extremely fine temporal scale, further research is needed on how to determine appropriate season and survey durations with respect to research questions.

### Objectives and applications

Authors have used the DOM in many ways to achieve their research aims. The most frequent objective for studies using DOMs was hypothesis testing, with 50% of authors expressing interest in a specific relationship. 31% were interested in identifying nondescript drivers of occupancy, 30% in estimating models parameters like occupancy themselves, and 29% worked to develop and expand on methods for DOMs. Just 10% of authors expressed interest in making predictions to unsurveyed locations or into the future. The DOMs ability to make predictions has been often underexploited in the existing literature, given its noted potential for forecasting occupancy in non-equilibrium scenarios [@kéry2013; @briscoe2021]. Articles which *do* make predictions provide some of the most directly applicable outputs found in the review sample. As examples, @mcgowan2020 provides projections for a threatened species under multiple putative management scenarios, and @pollentier2021 generates maps of distributions resembling those made with species distribution models (SDMs).

The authors of the studies captured in our sample come from a variety of backgrounds. 86% of articles had at least one author based at an academic institution, 46% had author(s) at government institutions and 25% had author(s) from non-profit organisations. The high proportion of articles with government and NGO participants suggests an applied focus for many users of DOMs. This has important implications: when a model is used to assess a critically endangered species [@carvalho2023], guide public health management of a disease vector [@mores2020], or track rapidly-developing biological invasions [@wood2020], it is imperative that models can be trusted to accurately represent a system. Regardless of the reasons why they turn to the DOM to analyse their data, authors must navigate the model building process.

# Practices in implementing DOMs

Approaches to building any type of model will necessarily depend on the possibilities of the data at hand and on the priorities of the model-builder. This precludes any prescription of the 'best' way to build a model; however, there may still be commonalities in the modelling workflow. The modelling process for both DOMs and SDMs can be divided into a few components. First, based on prior knowledge and ecological theory a suite of covariates with hypothetical relationships with model parameters is assembled. Next, some form of model selection procedure is followed to identify either a single optimal model, or an ensemble of suitable models to be used to make conclusions. Following this, a model's performance should be somehow assessed so that the validity of conclusions can be adequately judged. In this section we examine how DOM users have approaches each of these stages, and make comparisons to common practice in the more extensive SDM literature.

### Model complexity

'Complexity' is a broad term which encompasses many aspects of a model [@merow2014]. Opinions on simple versus complex models can be divided - some advocate for the simplest possible models, arguing that they are most generaliseable; others insist that overly-simple models cannot adequately represent the most important drivers in a system [@evans2013; @lonergan2014]. To account for imperfect detection and describe change in occupancy, DOMs must be somewhat more complex relative to static correlative occupancy models. This added complexity helps mitigate the bias introduced when important elements like imperfect detection are ignored. Within DOMs, however, further complexity is to some degree up to the modeller: they can choose how many covariates to consider for inclusion on the various parameters, and how to represent the nature of the relationship between those covariates and parameters.

The variation in the quality of covariates considered for each model parameter amongst our reviewed articles is shown in @fig-covariates. Notably, many studies expressed some parameters as a constant without including any covariates: of the four standard model parameters initial occupancy has the most articles considering zero covariates (35%) and detection probability the least (19%). A lack of any covariates on the initial occupancy parameter raises some questions. Presumably any taxa will have some amount of non-random variation in how it is distributed across a landscape; by expressing initial occupancy as a constant this heterogeneity is not captured. Omission of factors which drive occupancy can introduce bias into SDMs [@barry2006]. Initial occupancy is itself effectively a static correlative SDM, and the effects of poorly estimating this parameter on predicted occupancy in ensuing seasons is uncertain but unlikely to be favourable.

![Distribution of covariate quantity considered for each model parameter.](Figures/CovParamPlot.jpeg){#fig-covariates}

The types of covariates which were considered for modelling were also wide-ranging, and a summary of their inclusions in articles is presented in @tbl-covariates. The most frequently used covariates described aspects of habitat, with 57% of articles considering these terms for at least one parameter. Data for covariates may be either collected directly, requiring measurement at individual sites, or indirectly via remote sensing — where directly measured covariates may offer more direct insights, indirect measurements are far more easily projected to unsurveyed sites when making predictions [@austin2002]. Some covariates, like biotic interactions, must nearly always be measured at sites, while others such as climate and weather covariates are generally indirectly observed. There is variation in which covariates are most likely to be dynamic and change through time.

::: column-page-inset
```{r covariate table}
#| echo: false
#| message: false
#| label: tbl-covariates
#| tbl-cap: "All covariates considered for inclusion in a study were classified into mutually exclusive categories. For each parameter (initial occupancy, colonisation, extinction, and detection), the percentage of studies including at least one covariate in a given category is presented. We also present the percentage of covariates in each category which are dynamic (change throughout seasons) or require direct observation (e.g. are not remotely sensed). The percentage of covariates in each category for which non-linear representations or interactions with other covariates were considered is given to indicate which were most likely to be included as more complex terms."

library(tidyverse)
library(gt)

covTable <- read_csv("Figures/CovariateTable.csv")

covTable |>
  arrange(Category, -Prop_Any) |>
  gt(rowname_col = "Covariate", groupname_col = "Category") |>
  tab_options(
    row_group.as_column = TRUE
  ) |>
  tab_row_group(
    label = md("Environmental"),
    rows = Category == "E",
    id = "Env"
  ) |>
  tab_row_group(
    label = md("Structural"),
    rows = Category == "S",
    id = "Struct"
  ) |>
  tab_row_group(
    label = md("All"),
    rows = Category == "O",
    id = "All"
  ) |>
  tab_style(
    style = cell_fill(color = "#82AD8E"),
    locations = cells_row_groups(groups = "Env")
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "plum4")
    ),
    locations = cells_row_groups(groups = "Struct")
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "gray60")
    ),
    locations = cells_row_groups(groups = "All")
  ) |>
  row_group_order(groups = c("Env", "Struct", "All")) |>
  tab_spanner(label = "Articles with covariate on:",
              columns = c("Prop_Any", "Initial occupancy", "Occupancy",
                          "Colonisation", "Extinction_Persistence",
                          "Detection"),
              id = "inclusions") |>
  tab_spanner(label = "Covariates which are:",
              columns = c(Prop_Dynamic, Prop_Direct),
              id = "covariates") |>
  tab_spanner(label = "Articles representing with:",
              columns = c(Prop_Nonlinear, Prop_Interact),
              id = "representations") |>
   cols_label(
    Prop_Any = "Any parameter",
    `Initial occupancy` = html("&psi;1"),
    Occupancy = html("&psi;"),
    Colonisation = html("&gamma;"),
    Extinction_Persistence = html("&epsilon;"),
    Detection = html("&rho;"),
    Prop_Dynamic = "Dynamic",
    Prop_Direct = "Directly observed",
    Prop_Nonlinear = "Non-linear",
    Prop_Interact = "Interaction"
  ) |>
  text_case_match(
    "Environmental" ~ md("*Any Environmental*"),
    "HABT" ~ "Habitat type",
    .locations = cells_stub()
  ) |>
  cols_hide(Category) |>
  fmt_percent(decimals = 0) |>
  sub_missing(missing_text = "-") |>
  as_raw_html()
  
```
:::

For the vast majority of covariates authors considered only linear relationships with model parameters. Polynomial responses are rare — even in the categories where they are most frequently used, the rate of consideration for non-linear responses does not exceed 16%. This is a notable departure from SDMs; while GLM-based methods with linear responses are used, many common methods used to fit SDMs like MAXENT or boosted regression trees typically permit flexibility in response curves between covariates and parameters [@merow2013; @elith2008]. Non-linear relationships are the norm, not the exception in nature, and in many cases a linear response will not adequately capture a covariate's influence on model parameters [@austin2002]. Interactions between covariates were also rarely incorporate in our sample, and their rate of inclusion does not exceed 34% for any category. While they should not necessarily be used liberally, where these interactions exist their exclusion can influence model performance [@guisan2006].

Any model must balance simplicity and realism, but it is important that the ecological relationships quantitatively expressed in a model be grounded in ecological theory and accurately represent the modeller's hypothesised response [@austin2002; @austin2007]. Complexity in the quantity and nature of covariate responses is also controlled during model selection, but these procedures can only work with the information provided to them. Adequately considering the plausible drivers of occupancy and detection by identifying quality candidate covariates representing those drivers is an important step in developing robust models that appropriately account for heterogeneity in these parameters.

### Covariate selection

Variation in approaches to modelling is particularly apparent in the model selection process, where there is little consensus on how to determine which covariates to include in final models (@fig-selection). In the reviewed frequentist implementations, a range of approaches have been used for this purpose including comparison suites of candidate models defined *a priori* and various stepwise selection protocols. Bayesian implementations were far less likely to use model selection procedures — 70% of these fit only a single model defined *a priori,* relative to 10% amongst the frequentist models.

![Frequency of use for model selection methods. 'Single model' indicates no model selection occurred, 'candidate suite' includes studies which compared a predefined set of models, articles with 'procedural selection' fit parameters one-by-one, 'exhaustive selection' fit all possible combinations of models, and 'simple precursor' describes where results of a less-complex model were used to inform covariate choice.](Figures/SelectionFigure.jpeg){#fig-selection}

Model selection is a particularly challenging aspect of fitting DOMs, with substantial uncertainties in the best ways to conduct the process. Limited research has been conducted on the topic, but what has been done has indicated that choices in this process can influence the quality of model outputs [@morin2020]. This is reflected in research from outside the DOM literature, where stepwise protocols have been found to be unreliable [@olden2000]. However, others have found that different model selection methods can end up arriving at roughly the same answer [@maggini2006]. Model selection can be particularly difficult for DOMs given the increased complexity of the underlying model structure, which will often preclude exhaustive selection from amongst all possibilities.

Bayesian model selection is an effectively distinct question in DOMs as the framework is not well suited to the more conventional model selection methods. @hooten2015 provides a guide to some of the possibilities for optimising Bayesian models, including the use of regularisation priors.

Some reviewed studies included substantially more complex model selection protocols.

### Model validation

Regardless of whether a model was implemented under the Bayesian or frequentist frameworks, evaluation of model fit or performance was rare. Only 8% of articles directly addressed either aspect of modelling, be it via goodness-of-fit tests or validation with either internal or external data. This is a striking departure from the SDM literature, where roughly half of studies sufficiently assess their models performance [@araújo2019]. While the appropriate method of model evaluation may depend on data availability and research objectives, assessing models by some method is always important to ensure reliability of model outputs [@araújo2005; @guisan2005]. Most models in our sample conduct model selection using AIC as a scoring criteria, and often using model averages. While these approaches provide *relative* models of fit, they cannot be considered evaluation themselves - as @mackenzie2004 write, "the selection of a 'best' model(s) does not guarantee the selection of a "good" model.

The first goodness-of-fit (GOF) test for occupancy model was given in @mackenzie2004, implemented via a parametric bootstrap. There is no GOF test available for DOM, however, common packages including 'AICcModAvg' and 'unmarked' offer parametric bootstraps derived from @mackenzie2004's test which have been used by some authors in our sample. While these tests may not suit Bayesian implementations, @broms2016 discusses possibilities for model evaluation in that context - while their article focuses on single-season multi-species occupancy models, extensions of their approach may suit the dynamic multi-season model as well.

All aspects of modelling varied with the stated objectives of articles (@tbl-objectives). Those focussed on making predictions and identifying drivers of occupancy were more likely to consider a larger number of covariates and represented covariates in more complex ways by considering non-linear responses and interactions between covariates. Articles with objectives involving methods development considered fewer covariates and were less likely to use these more complex formulations.

<div>

```{r Objectives table}
#| echo: false
#| message: false
#| label: tbl-objectives
#| tbl-cap: "Implementation of models by study objective. Models were assessed based on the number of covariates considered, the inclusion of non-linear responses and interactions between covaraites, the manner of model selection, and whether or not they objectively evaluated model performance."

objTable <- read_csv("Figures/ObjectiveTable.csv")

objTable |>
  mutate(Objective = fct(Objective,
                         levels = c("Hypothesis", "Drivers", "Parameters",
                                    "Methods", "Predict", "Any"))) |>
  arrange(Objective) |>
  mutate(Objective = case_when(Objective == "Hypothesis" ~ "Testing hypotheses",
                               Objective == "Drivers" ~ "Identifying drivers",
                               Objective == "Predict" ~ "Making predictions",
                               Objective == "Methods" ~ "Developing methods",
                               Objective == "Parameters" ~ "Estimating parameters",
                               Objective == "Any" ~ "Any objective")) |>
  gt(rowname_col = "Objective") |>
  tab_spanner(label = "Articles",
              columns = c("Articles", "ArticlesProp"),
              id = "articles") |>
  tab_spanner(label = "Percent which have:",
              columns = c("ProbPoly", "ProbInt",
                          "ProbEval", "ProbSelect"),
              id = "percents") |>
  cols_label(Articles = "n", ArticlesProp = "%",
             MedianCovs = "Median covariates considered",
             ProbPoly = "Non-linear responses",
             ProbInt = "Covariate interactions",
             ProbSelect = "Model selection",
             ProbEval = "Model evaluation / goodness of fit") |>
  fmt_percent(columns = c(ArticlesProp, 
                          ProbPoly, ProbInt, 
                          ProbEval, ProbSelect),
              decimals = 0) |>
  tab_style(style = list(cell_fill(color = "gray80"),
                         cell_text(style = "italic")),
            locations = cells_body(rows = Objective == "Any objective")) |>
  tab_style(style = cell_fill(color = "lavender"),
            locations = cells_body(columns = MedianCovs,
                                   rows = MedianCovs == max(MedianCovs, na.rm = TRUE))) |>
  tab_style(style = cell_fill(color = "lavender"),
            locations = cells_body(columns = ProbPoly,
                                   rows = ProbPoly == max(ProbPoly, na.rm = TRUE))) |>
  tab_style(style = cell_fill(color = "lavender"),
            locations = cells_body(columns = ProbInt,
                                   rows = ProbInt == max(ProbInt, na.rm = TRUE))) |>
  tab_style(style = cell_fill(color = "lavender"),
            locations = cells_body(columns = ProbEval,
                                   rows = ProbEval == max(ProbEval, na.rm = TRUE))) |>
  tab_style(style = cell_fill(color = "lavender"),
            locations = cells_body(columns = ProbSelect,
                                   rows = ProbSelect == max(ProbSelect, na.rm = TRUE))) |>
  as_raw_html()
```

</div>

# Conclusions and key considerations

Our review highlights the dynamic occupancy model's exceptional flexibility and suitability to addressing a range of ecological questions. The DOM may be a more achievable option than many think with feasible options to incorporate much existing presence/absence data from a variety of sources. Fertile areas for future research remain, with methods and guidance for making predictions and for modelling autonomous detection data from camera-traps and acoustic monitors particularly promising opportunities. In light of this potential and the DOMs status as a popular tool for applied ecology, it is increasingly important that best-practice standards be established for building these models. Major questions remain on fundamental questions in model building — there is need for further research on the appropriate levels of complexity for DOMs in various scenarios, on the methods for selecting models from amongst candidates, and on the best ways to evaluate the quality of the models chosen. In these areas, DOMs lag well behind SDMs where these standards have been more seriously considered [@araújo2006; @araújo2019; @zurell2020]. Given the parallels between these model classes, we may be able to extrapolate some lessons from SDMs to support building better DOMs. In light of these uncertainties, and based upon existing research on SDMs, we discuss some key considerations for authors seeking to use DOMs in their work:

I.  **Are key drivers of occupancy and detection incorporated?** While it is effectively impossible to *fully* describe heterogeneity across a landscape, authors should make their best efforts to capture the drivers of occupancy and detection most likely to influence their study species. This is true even when another covariate is of principal interest to investigators — failure to include other major determinants of occupancy is likely to bias parameter estimates. One place where this is of particular importance is in determining drivers of detection, which is not only subject to observational conditions but also ecological determinants which may cause the species to spend more time at a location and thus be more frequently available for detection.

II. **Do covariates relationships reflect ecological complexity?** Many ecological relationships are non-linear and may require polynomial terms to be accurately represented. This is particularly true at large spatial scales where a larger portion of a species ecological niche is represented in surveyed data. Authors should question whether a linear term is sufficient to capture hypothetical relationships in their study systems, and consider representing species responses as polynomials terms where appropriate. Interactions between covariates should also be explored where a plausible ecological relationship between factors exists.

III. **How should model evaluation be conducted?** Regardless of why a model is used, it is important to assess its quality and its ability to support the conclusions drawn from it. While more research is needed on the most robust ways to assess models, existing methods should be used and reported in published studies. Dependent on data availability and model objectives, this can be achieved through bootstrapped goodness-of-fit tests or metrics of predictive performance on reserved data. This is an important step in establishing best-practices for the field, and should realistically be conducted in some form for the vast majority of studies.

As previously stated, DOMs and their outputs are important — in a biodiversity and conservation context where quantitative representations of complex natural systems are used to guide policy and decision making, it is necessary to ensure models can be trusted. We hope that this review can open a broader discussion on how to best approach dynamic occupancy modelling as a first step towards establishing best practices in the discipline.
