---
title: "Twenty years of dynamic occupancy models: a review of applications and look towards the future"
date: today

authors:
  - name: Saoirse Kelleher
    affiliation: University of Melbourne
    email: saoirse.kelleher@student.unimelb.edu.au
    orcid: 0000-0002-4614-5753
    corresponding: true
  - name: Natalie Briscoe
    affiliation: University of Melbourne
  - name: Gurutzeta Guillera-Arroita
    affiliation: Pyrenean Institute of Ecology, Spanish National Research Council
  - name: Jane Elith
    affiliation: University of Melbourne
    
abstract: | 
 Since their introduction over twenty years ago, dynamic occupancy models (DOMs) have become a powerful and flexible framework for estimating species occupancy across space and time while accounting for imperfect detection. As their popularity has increased and extensions have further expanded their capabilities, DOMs have been applied to increasingly diverse datasets and research objectives in applied ecology. At the same time, technological advancements have resulted in massive increases in available data, offering both new opportunities and new challenges for users of DOMs. Given these developments, it is timely to examine common practices in building these models to understand the breadth of modelling approaches, determine potential vulnerabilities, and identify priorities for future research. We reviewed a sample of articles that have fit DOMs in the past 20 years, examining the contexts of their application and the approaches taken to the model building process. We find that these models have been used to pursue diverse objectives, based on datasets with wide-ranging spatial and temporal scales collected using a variety of survey methods. Our comparisons of modelling approaches indicate that many applications of DOMs considered relatively few covariates on key model parameters, as well as a tendency towards linear responses over more complex non-linear or interactive forms. Model selection techniques were largely idiosyncratic with little consensus on the best approaches, and model evaluation was rare across reviewed applications ‚Äì additionally, existing research on either of these subjects is limited. Based on these findings, we identify key areas of the modelling process which merit discussion and further investigation. Where possible we provide recommendations for current users of DOMs, and where uncertainties remain, we highlight key priorities for future research to support users in fitting the most reliable and useful models possible. 

format:
  html:
    theme: simplex
    mainfont: Georgia, serif
  docx: default

embed-resources: true
title-block-banner: true
---

# Introduction

The description of patterns of species occupancy across landscapes has been a long-standing subject of ecological research [@humboldt1849]. Estimates of how widespread a species is and where it occurs are the foundation of monitoring programs and important for assessing conservation status, while identifying potential drivers of occurrence can help inform potential management actions [@mackenzie2013]. Robust knowledge of the occupancy patterns of a species can also help us to predict where a species is most likely to occur, both under present conditions and in hypothetical future scenarios [@k√©ry2013].

Irrespective of its importance, ‚Äòoccupancy‚Äô ‚Äì broadly referring here to the presence of a species in a given area and time period ‚Äì has proven to be a persistently difficult quantity to estimate in practice. This difficulty arises from the challenges inherent in modelling complex and dynamic natural systems with incomplete data, exacerbated by the fact that it is often impossible to determine whether a species is truly absent from a site or whether it was simply not detected. It is well-established that imperfect detection of organisms results in biased estimates of occupancy [@gu2004; @lahoz-monfort2014]. Despite this fact and the ubiquity of imperfect detection in field data, many models in widespread use make no adjustments for detection [@kellner2014]. In addition to this limitation, many models currently in use (such as conventional correlative species distribution models) are ill-suited for predicting to new locations and time periods [@dormann2007; @elith2010]. These shortcomings are particularly pronounced when modelling biological invasions and climate change driven range shifts, both of which are management priorities that are increasingly commonplace in the Anthropocene [@bertelsmeier2013; @lenoir2015].

In recent years, awareness of these obstacles to accurate occupancy estimation and the limitations of many popular methods has encouraged interest in a variety of process-explicit models better suited to these contexts [@briscoe2019]. These include ‚Äòdynamic occupancy models‚Äô (DOMs), first introduced by @mackenzie2003 as an extension to earlier static site occupancy models [@mackenzie2002]. In their simplest form DOMs use hierarchical observation data to estimate changing site occupancy over time while correcting for imperfect detection; an overview of the basic form and requirements of these models can be found in Box 1. By accounting for imperfect detection and explicitly modelling colonisation and extinction to describe changes in site occupancy DOMs provide answers to common issues in occupancy estimation and offer important advantages over other models [@guillera-arroita2017a]. Alongside these advantages, they require only relatively simple-to-collect detection/non-detection data rather than the detailed demographic or abundance data required by other more process-explicit models [@briscoe2019]. This balance between complexity and feasibility makes DOMs an appealing option for many applied ecologists.

::: {#nte-Primer .callout-note icon="false"}
## An introduction to dynamic occupancy models

DOMsare hierarchical models that link observed detection/non-detection data with the underlying latent process of changing site occupancy. To do this, they contain two [sub-models]{.underline}: one describing the ecological process of sites shifting between unoccupied and occupied states over time, and one describing the observation process that records whether a species is detected during surveys given its presence at a site.

**Input data:** To separate these two processes DOMs require hierarchical data inputs. Occupancy is estimated at independent sites *(i)* during discrete, time-bound intervals termed ‚Äòprimary occasions‚Äô *(t)*. Within primary occasions*,* multiple observations are made at the same sites during independent ‚Äòsecondary occasions‚Äô *(j).* For each observation, a species is either detected (y~i,t,j~ = 1) or not (y~i,t,j~ = 0), resulting in a three dimensional detection matrix as shown in the example below. It is not necessary for all primary occasions to contain the same number of secondary occasions, and missing observations at sites can be accommodated. While secondary occasions are most often represented as repeat observations, other options including same-visit replicates and spatial replicates may also be used [@guillera-arroita2017a].

![](Figures/B1_RobustDesign.png){fig-align="center"}

**Occupancy sub-model:** Changing site occupancy over time is described as a Markovian process as represented in the graphic below. In each primary occasion *t,* each site *i* may exist in either an occupied (z~i,t~ = 1) or unoccupied state (z~i,t~ = 0). In the first primary occasion, occupancy is determined by a Bernoulli trial with initial occupancy probability ùõô~1~, such that $z_{i,t=1} \sim Bernoulli(\psi_1)$. In subsequent primary occasions, site occupancy is determined by the site's state in the previous primary occasion and probabilities of colonisation ùõÑ and extinction ùõÜ, such that $z_{i,t} \sim Bernoulli(z_{i,t-1}(1-\epsilon)+(1-z_{i,t-1})*\gamma)$.

![](Figures/B2_Occupancy.png){fig-align="center"}

**Observation sub-model:** The detection process relates the observed data **y** to the latent occupancy states **z** as shown in the below graphic. During any given secondary occasion *j* within primary occasion *t* at site *i,* observers will either observe (y~i,t,j~ = 1) or not observe (y~i,t,j~ = 0) the target species. The probability of observation is given as a Bernoulli trial with detection probability *p,* conditioned on the site being occupied in primary occasion *t* such that $y_{i,t,j} \sim Bernoulli(z_{i,t}*p)$.

![](Figures/B3_Detection.png){fig-align="center"}

In their original formulation, DOMs estimate four parameters of interest: initial occupancy (ùõô~1~), colonisation (ùõÑ), extinction (ùõÜ), and detection (*p)*. While we have represented each of these parameters as constants for simplicity, they are more often modelled as time-dependent or estimated with respect to covariates. These covariates are typically incorporated via a logit link function, such that DOMs can be considered four interconnected generalised linear models.

Conventional DOMs make several important assumptions: i) sites are closed to changes in true occupancy state within each primary occasion, ii) occupancy at each site is independent of other sites, iii) observations within each primary occasion are independent of each other, iv) no false positive detections occur, and v) key sources of heterogeneity (including in detectability) are modelled.

For more detailed information on DOMs and related models, see [@mackenzie2017] and [@k√©ry2021].
:::

Over the past two decades, continued research on DOMs and occupancy models more broadly has established a powerful and flexible modelling framework suitable for many common tasks in ecological research. Uptake of these models has been encouraged by the availability of freely available software tools for fitting DOMs, which include the program PRESENCE and the R package *unmarked* for fitting the models by maximum likelihood estimation [@hines2006; @kellner2023]*.* In the Bayesian context, resources such as @k√©ry2021 ‚Äôs text on hierarchical modelling in JAGS and the *ubms* R package have helped to increase the accessibility of these implementations [@kellner2022]. Various model extensions have further broadened DOMs‚Äô capabilities ‚Äì these include models that can account for false positives [@royle2006; @miller2011], model multiple states beyond occupied and unoccupied [@nichols2007], and jointly estimate occupancy for multiple species [@dorazio2010; @devarajan2020]. For more details on using these extensions, see reviews by @bailey2014 and @guillera-arroita2017a.

Coinciding with these developments, recent years have seen substantial changes in how ecologists conduct their research. The amount of data available for modelling (including species detections as well as environmental data) has grown considerably over time due to a range of factors, including improvements to data sharing, new large-scale monitoring programs, and increased interest in citizen science efforts [@farley2018; @altwegg2019]. Technological advances have facilitated the widespread deployment of autonomous detection methods including camera traps and acoustic monitors, generating large quantities of observation data suitable for analysis with DOMs [@balantic2019; @lahoz-monfort2021]. At the same time, advancements in computing have made methods which may have been too computationally expensive in the past far more accessible for many. While these advances create exciting new opportunities, they also introduce new challenges for users who must navigate a complex model building process to produce useful and reliable models. Where researchers on related species distribution models have built a large body of literature on assessing various approaches to model building including covariate inclusion and model selection, comparatively little research on these topics has been published for DOMs despite additional complications in performing these tasks for hierarchical models [@guisan2017].

### Objectives

To understand how users have applied DOMs over the past two decades, we conducted an in-depth review of studies implementing these models since their introduction. We first identify the research contexts where DOMs have been used, characterising the research objectives they have been applied to, the scale and characteristics of the study systems where data was collected, and the methods used to collect and format the data used to fit models. We then review approaches taken to the modelling process, including the nature of the covariates considered for inclusion and the form of their relationships in the model, the methods used for model selection, and the reporting of model assessment and evaluation. By jointly considering the research contexts to which DOMs are now applied and the approaches taken for model building and evaluation, we aim to highlight challenges in building DOMs, providing recommendations where possible and identifying priorities for future research where uncertainties remain.

# Methods

Our review was constrained to applications of the dynamic occupancy model of @mackenzie2003 and its extensions. To be included, articles must have fit models that met the following criteria:

i.   Used non-simulated, field-collected, detection/non-detection data.

ii. Included data from multiple sites which could exist in at least two states, including an occupied and unoccupied state.

iii. Included data from multiple primary occasions, between which sites change states conditional on the prior occasion‚Äôs occupancy state and transition probabilities such as colonisation and extinction.

iv. Contained at least one parameter describing the detection process.

A pool of candidate articles was generated using two queries on Web of Science on July 26 and July 29, 2024. The first query included all articles from 2004-2023 which cited @mackenzie2003. To capture additional relevant articles that did not directly cite @mackenzie2003, a second query was generated to search articles in the same time-span matching the terms ‚Äú*dynamic occupancy model\**‚Äù, ‚Äú*multi-season occupancy model\**‚Äù, or ‚Äú*occupancy dynamic\**‚Äù; articles including each of ‚Äú*occupancy*‚Äù, ‚Äú*colonization*‚Äù, ‚Äú*extinction/persistence*‚Äù, and ‚Äú*detection*‚Äù; and articles with the term ‚Äú*occupancy*‚Äù located near ‚Äú*dynamic*‚Äù in the title, key terms, or abstract. These queries resulted in 1469 articles: 897 retrieved only from the MacKenzie citations, 274 only from the keywords search, and 298 which appeared in both queries. To allow comparison of DOMs through time, we divided all articles across five four-year strata spanning 2004-2007, 2008-2011, 2012-2015, 2016-2019, and 2020-2023. From each stratum we randomly selected 20 articles for inclusion in the review. Articles that did not meet inclusion criteria were replaced from within their own stratum unless no articles remained. For each article we documented details on the research contexts, datasets, and modelling processes as outlined below.

### Research objectives

We allocated each article to research objective categories based on the aims stated in the text. The six non-exclusive categories included i) ‚Äòestimating trends‚Äô, where authors expressed interest in estimates of site occupancy, colonisation, extinction, or detection probabilities; ii) ‚Äòtesting relationships‚Äô, where authors examined predefined hypothesised relationships between covariates and model parameters; iii) ‚Äòidentifying drivers‚Äô, where authors more broadly explored covariates associated with model parameters; iv) ‚Äòpredicting temporally‚Äô, where authors predicted site occupancy under future conditions; v) ‚Äòpredicting spatially‚Äô, where authors predicted site occupancy to unsurveyed locations; and vi) ‚Äòdeveloping methods‚Äô, where authors introduced, tested, or demonstrated aspects of DOMs.

### Study systems

We recorded the approximate geographical location, spatial scale, and target taxa for each study system in the reviewed articles. In cases where a single article included DOMs fit to data from multiple study systems, we recorded details for each dataset that was analysed independently. A study system‚Äôs spatial scale was defined as the intended area of inference containing all sites, measured to an order of magnitude to account for uncertainty in reporting. Details collected on target taxa included the total number of taxa modelled, their general categorisation (birds, mammals, herptiles, invertebrates, or ‚Äòother‚Äô), and their conservation status. Taxa were denoted as threatened if they were listed on the IUCN Red List of Species as of 2024 or if authors explicitly stated that they were threatened [@iucn]. This deference to authors‚Äô representation of conservation status was made to account for sub-species which lack listings or species which are of more local concern, although we acknowledge that in some cases conservation status may have changed since publication.

### Observations and data structure

For each article, we recorded how observation data was collected for use in modelling. Categories of survey methods included human observations, physical trapping, camera traps, and acoustic monitors. Within these categories we also indicated whether any observations were collected by citizen scientists, either as part of structured survey programs or as more *ad hoc* observations. Details collected on each dataset‚Äôs structure included the number of primary and secondary occasions, the time elapsed between the first and last survey, and the number of sites used for modelling.

### Covariates and complexity

We were interested in the types and quantities of the covariates considered by authors. To this end, we recorded all covariates considered in each study regardless of whether they were included in final models, acknowledging that not all covariates considered are always reported. Key traits of each covariate were recorded including a general categorisation (see supporting information), whether they were directly observed or remotely sensed, whether they were static or varied between primary occasions, and how they were represented in the model: as a linear response, a non-linear response, or part of an interaction with another covariate [@james2021]. In some cases, a single article included distinct modelling workflows with different candidate covariates. Covariates were recorded for each of these workflows independently.

### Model selection and assessment

Model selection procedures were sorted into non-exclusive categories including ‚Äò*a priori‚Äô*, where only one model was considered; ‚Äòcandidate set‚Äô, where a predefined set of models was considered; ‚Äòsequential‚Äô, where covariates were selected parameter-by-parameter (e.g., fitting detection first, followed by initial occupancy and so on); and ‚Äòsimple precursors‚Äô, where covariate selection was preceded by tests with a simpler model implementation such as a linear regression or single season occupancy model. We also indicated whether model averaging was used for multi-model inference @burnham2004. For each modelling workflow, we documented whether goodness-of-fit was tested and reported, and whether model performance was assessed by validation with either in-sample or out-of-sample data.

# Results

92 articles were included for this review, fewer than the 100 possible articles due to a deficit of qualifying papers in the first stratum (2004-2007). All review data is available in the supporting information. Based on the acceptance rates within each stratum and the number of unprocessed articles remaining for each year, an estimated 496 of 1152 unprocessed articles in our sample would have met inclusion criteria, with an apparent increase over time in the number of articles fitting DOMs (@fig-coverage).

![Bars indicate the estimated number of articles fitting DOMs in each year, with green representing articles included in our review and grey projected remaining qualifying articles. Projections were calculated using the number of unprocessed articles remaining in each year multiplied by the acceptance rate of the corresponding stratum: 12% of queried articles from 2004-2007; 24% from 2008-2011; 42% from 2012-2015; 35% from 2016-2019; and 57% from 2020-2023.](Figures/1_CoveragePlot.png){#fig-coverage}

### Research objectives

DOMs have been used to achieve varied research objectives, with no one category of objective representing over half of usage and 37% of studies having pursued multiple objectives simultaneously (Figure 2). The most frequent use of DOMs (44% of studies) was to test hypothesised relationships between environmental factors and species occupancy, often targeting core conservation priorities for their focal species as demonstrated by @olson2005 ‚Äôs early study assessing the influence of barred owls (*Strix varia)* on the threatened spotted owl (*Strix occidentalis*). 35% of studies took a more exploratory approach to identifying possible drivers of occupancy, such as in @huber2017 ‚Äôs study that examined dozens of habitat covariates for wood warbler (*Phylloscopus sibilatrix*) occupancy. An additional 36% of articles used DOMs to monitor trends in occupancy state through time, both for single species of high conservation interest and for broader community assemblages of species [@ahumada2013; @scott2015]. While only 17% of articles used their DOMs to make predictions, the proportion of articles pursing this objective has increased in recent years. These studies tended to have a strong conservation focus, as with @mcgowan2020 ‚Äôs projections of future occupancy for wetland birds under alternative management scenarios. Finally, 22% of the papers reviewed focused on methods development, representing continued focus on extending and testing DOMs.

The applied nature of studies fitting DOMs is further reflected in their authorship: while 79% of studies included at least one affiliate of an academic institution, 59% included a government affiliate, 28% an NGO affiliate, and 12% an affiliate of a private company. 63% of studies had cross-sector authorship with affiliations from at least two categories.

![Bars represent the percentage of articles which pursued each of six non-exclusive research objectives. These objectives include articles which demonstrated methods for DOMs, estimated trends in model parameters, identified drivers of occupancy dynamics, tested hypothesised relationships with the environment, made spatial predictions, and made temporal predictions. Percentages are given for each four-year stratum (n = 12 articles for 2004-2007; n = 20 for all other strata), as well as for all articles in the review sample (n = 92).](Figures/2_Objectives.png){#fig-Objectives}

### Study systems

The study systems included in our sample were globally distributed: while a majority of articles used data collected in the United States of America, study systems spanned all continents except Antarctica (@fig-StudyDetails A). These study areas varied considerably in size, ranging from hyper-local to continental scales (@fig-StudyDetails B). The smallest study locality included in our sample explored insect occurrence in a rainforest plot less than one square kilometre, while the largest analysis modelled avian range shifts across the entire eastern half of the United States [@clement2019; @basset2023].

Most studies focused on vertebrate taxa (@fig-StudyDetails C), particularly birds and mammals. DOMs have been less frequently applied to non-animal organisms, perhaps due to a reduced emphasis on imperfect detection outside of the wildlife modelling community. However, there were exceptions, including studies that used DOMs to model decadal changes in lichen occupancy, the spread of chronic wasting disease, and mosquito dynamics [@belinch√≥n2017; @mores2020; @cook2022]. The vast majority of studies model terrestrial species, though there have been a limited number of studies on aquatic taxa including invasive salmon, Great Plains stream fishes, and whales [@falke2012; @fisher2014; @pendleton2022].

While most studies fit models for a single taxon (either a single species or multiple species lumped together), 44% fit models to multiple distinct taxa (@fig-StudyDetails D). 34% of studies fit independent models to multiple species [@otto2012; @peach2019], whereas 12% used explicitly multi-species extensions of DOMs. The latter included hierarchical models which fit hundreds of species in a single implementation with species-level effects [@dorazio2010; @hendershot2020] as well as explicit interaction models which estimated conditional occupancy, colonisation, extinction, and detection probabilities [@lesmeister2015; @fidino2019].undefined

![A summary of the research contexts in reviewed applications of DOMs. a) The approximate locations of the study areas where data was collected. b) Spatial extent of the study areas, defined as the area of inference within which all surveyed points were contained. c) Number of articles that fit models to each taxa category. Taxa are considered ‚Äòthreatened‚Äô if indicated by authors or they are listed on the IUCN Red List. d) The number of taxa modelled as distinct groups in each application. Explicitly multi-species models include both hierarchical jointly estimated models and more interactive models. e) Number of articles using each method for capturing detection/non-detection data. These are non-exclusive, and citizen science data is a subset of ‚Äòdirect observations.‚Äô (f) The number of sites and study duration for each dataset used to fit DOMs ‚Äì gold lines indicate medians.](Figures/3_StudyContexts.png){#fig-StudyDetails}

### Observations and data collection

The detection/non-detection data required for DOMs was collected using various survey methods across reviewed studies (@fig-StudyDetails E): 79% of studies used direct observation data, 11% used live-trapping methods, and 14% used detections from camera traps. Within these categories, 10% of studies used citizen science data. Citizen science data included coordinated surveys at backyard bird-feeders as well as interviews with civilians on sightings of tiger (*Panthera tigris*) signs [@zuckerberg2011; @warrier2020]. Datasets ranged considerably in size, with the smallest including observations at just 10 sites and the largest including over 6000 (@fig-StudyDetails F); the median dataset included 100 sites. The temporal scale of studies shows similar variability ‚Äì time elapsed between the first and last survey ranged from under one month to over forty years (median 8 years), and the number of primary occasions ranged from 2 to 189 (median 6 occasions).

Notably, not all of these datasets were originally collected in a hierarchical structure with DOMs in mind. In these cases, authors formatted their data into a hierarchical format *post-hoc* using a variety of methods. Some defined primary occasions as arbitrary discrete time intervals, treating all surveys occurring within a window as secondary occasions; others defined sites as larger grid cells, treating any survey falling within the grid as a spatial replicate. For example, in the only application of DOMs to marine species in our sample, @pendleton2022 used aerial transects broken up into grid cells to observe whale occupancy. In another example with grid cells, @marescot2020 fit a multi-species model treating poachers as a taxon and using ranger reports from each cell to create detection histories. These manipulations permit use of data predating DOMs, with one study using surveys conducted by Joseph Grinnell in 1908 to model century-long changes in occupancy [@riddell2021].

### Covariates and complexity

The most common covariates considered for use in DOMs addressed aspects of habitat and land cover [@fig-CovariateSummary]. 35% of studies incorporated covariates for site geometry and connectivity, such as habitat patch size or distance to other sites. Often these were included as simple covariates on colonisation or extinction, such as the distance to other sites or landscape habitat connectivity metrics [@duggan2011]. Alternatively, more complex parameterisations explicitly modelled colonisation or extinction as a spatial process dependent on patch size or the distance to occupied sites [@risk2011; @broms2016]. Several studies also included biotic interactions with other species as covariates, often where the target taxon was threatened by invasive species. These covariates effectively incorporate species interactions in DOMs without requiring the use of more complex explicitly multi-species models.

![Attributes of the covariates considered for inclusion in DOMs. Columns represent the percentage of studies that tested at least one covariate in a category on any model parameter (a), and the average percentage of covariates in each category that were (b) time-varying, excluding covariates on initial occupancy, (c) directly observed at each site, and (d) considered with non-linear terms or interactions with other covariates. To avoid the dominance of studies considering large amounts of covariates in b-d, we first calculated the relevant percentage of covariates per study then took the mean. Covariates were classified as either environmental factors representing plausible ecological correlates of model parameters, or structural factors related to the model form or observational details that distinct from the environment. Environmental categories included ‚ÄòHabitat‚Äô ‚Äì land cover and habitat features; ‚ÄòSpatial‚Äô ‚Äì site dimensions and physical location; ‚ÄòClimate‚Äô ‚Äì weather and long-term climate; ‚ÄòTiming‚Äô ‚Äì chronology with ecological relevance; ‚ÄòHuman‚Äô ‚Äì interaction with anthropogenic activity; ‚ÄòTopography‚Äô ‚Äì geologic features; ‚ÄòBiotic‚Äô -- any potential predator/prey/competitor interactions; and ‚ÄòWater‚Äô ‚Äì hydrologic features. Structural categories included ‚ÄòPrimary‚Äô ‚Äì effect of the primary occasion; ‚ÄòObservation‚Äô ‚Äìobservation method and characteristics; ‚ÄòSecondary‚Äô ‚Äì effect of the primary occasion; ‚ÄòSite‚Äô ‚Äì site-level effects; and ‚ÄòSpecies‚Äô ‚Äì species-specific effects. We also provide summaries across all covariate categories (‚ÄòAny‚Äô), all environmental covariates (‚ÄòAny Env‚Äô), and all structural covariates (‚ÄòAny Struct.‚Äô). For more verbose definitions and analysis code, see supplementally materials.](Figures/4_CovariateSummary.png){#fig-CovariateSummary}

Covariate data for studies in our sample were either collected directly during surveys by researchers (an average of 30% of environmental covariates per study), or derived from pre-existing remotely sensed datasets (70% of environmental covariates); this varied depending on the category of covariate [@fig-CovariateSummary]. Directly collected data often represented finer-scale factors like prey species occurrence or details of habitat structure, which can be difficult to measure remotely. An average of 43% percent of the environmental factors and 94% of the structural factors considered for time-varying parameters were dynamic covariates, with terms relating to climate or weather most frequently dynamic [@fig-CovariateSummary].

In conventional DOMs, covariates for each parameter are incorporated via a logistic regression (i.e., a linear regression through a logit link function; @mackenzie2017). Statistical relationships between model parameters and covariates (e.g., between initial occupancy and its environmental covariates) are represented as linear terms unless more complexity is specified, although non-linear responses can be easily accommodated in DOMs by using polynomial transformations and interactions between covariates. Despite this, in our sample only 35% of articles tested one or more non-linear responses to an environmental covariate, with most studies representing all covariates as simple linear terms. Interactions between covariates were similarly rare, with only 24% of studies considering at least one interaction between terms.

The size of the covariate pool for each parameter varied substantially, with the number of covariates considered ranging from 0 (effectively modelling the parameter as a constant) to over 40 candidates on a single parameter (@fig-CovariateCount). Note that this does not represent the number of covariates included in the final model formulation used for inference. The median number of covariates considered varied by parameter, with transition probabilities (colonisation and extinction) more likely to have a broader range of environmental covariates considered compared to initial occupancy and detection. The lack of any covariates considered for initial occupancy in 37% of studies is particularly notable, as is the observation that 30% of modelling workflows considered no environmental covariates for detection probability.

![The number of covariates considered for each core parameter across all distinct modelling workflows in our sample. A covariate is defined here as a distinct variable considered for inclusion, with linear, non-linear, and interactive forms of the same factor counted as a single covariate. Covariates are either ‚Äòenvironmental‚Äô, representing plausible ecological correlates of model parameters, or ‚Äòstructural‚Äô, relating to factors without direct ecological relationships. The ‚ÄòOccupancy\*‚Äô category here corresponds with alternative parameterisations of DOMs that jointly estimate occupancy, colonisation, and detection with extinction being only a derived parameter; this contrasts with more popular initial occupancy/colonisation/extinction/detection parameterisations.](Figures/5_CovariateCount.png){#fig-CovariateCount}

### Model selection and assessment

The 92 articles in our sample included 102 distinct modelling workflows. Of these models, 76 were fit by maximum likelihood estimation (MLE) and 24 were Bayesian implementations. 2 models fell into neither category and instead used machine learning based methods [@joseph2020].

In most cases, the DOMs fit in a study did not use all covariates initially considered for inclusion: 80% of modelling workflows included some form of model selection approach to identify a final model or set of models to make inferences from [@tbl-modelling]. Approaches varied between the MLE and Bayesian implementations in our sample; where 95% of MLE models performed some manner of model selection, only 33% of Bayesian models did so, with the majority instead fitting a single model defined *a priori*. For MLE models the most popular and conventional approach to model selection (45% of models) involved the creation of a candidate set of models, where the best model(s) was selected according to the lowest AIC score. The next most popular method in MLE studies was to use sequential model selection methods (37% of models), where the structure for each model parameter was fit in sequence. For example, a protocol might have first identified the best structure for detection probability while holding the other parameters constant, before moving on to initial occupancy and so on until all parameters were fixed. The remainder of MLE studies (8%) used a variety of other approaches, such as fitting simpler models like single season occupancy models to identify the most informative covariates to use in a dynamic occupancy model. Across all MLE implementations, 47% of articles used multi-model inference by model-averaging with AIC weights [@burnham2004].

```{r Table_Modelling}
#| echo: false
#| message: false
#| label: tbl-modelling
#| tbl-cap: "A summary of modelling practices in DOMs subset by framework (maximum likelihood or Bayesian). Some studies include multiple distinct modelling workflows (n = 102 workflows across 92 articles). 2 models included in the ‚ÄòAll models‚Äô column were neural network based and fell into neither the MLE or Bayesian categories. The model selection methods represented in this table are non-exclusive and some articles employed multiple approaches."
 
library(tidyverse)
library(gt)
modellingSummary <- read_csv("Figures/T2_ModellingSummary.csv") |>
  rename(`MLE` = Frequentist)

modellingSummary |>
  mutate(Variable = fct(Variable, 
                        levels = c("Number", "MedianCovs", 
                                   "Prop_AnySelect", "Prop_Candidate",
                                   "Prop_Sequential", "Prop_Simple",
                                   "Prop_ModAvg", "Prop_GOF", 
                                   "Prop_Eval"))) |>
  arrange(Variable) |>
  mutate(Variable = as.character(Variable)) |>
  gt(rowname_col = "Variable") |> 
  tab_row_group(
    label = "Covariate selection methods",
    rows = c("Prop_AnySelect", "Prop_Candidate",
             "Prop_Sequential", "Prop_Simple", "Prop_ModAvg"),
    id = "select"
  ) |>
  tab_row_group(
    label = "Model evaluation conducted",
    rows = c("Prop_GOF", "Prop_Eval"),
    id = "eval"
  ) |>
  row_group_order(groups = c(NA, "select", "eval")) |>
  text_case_match("Number" ~ "Number of workflows",
                  "MedianCovs" ~ "Median covariates considered per parameter",
                  "Prop_ModAvg" ~ "Percentage using model-averaging",
                  "Prop_AnySelect" ~ "Percentage using any model selection approach",
                  "Prop_Sequential" ~ "Percentage using sequential model selection",
                  "Prop_Simple" ~ "Percentage selecting covariates with simpler models",
                  "Prop_Candidate" ~ "Percentage comparing models in a candidate set",
                  "Prop_GOF" ~ "Percentage calculating goodness-of-fit",
                  "Prop_Eval" ~ "Percentage assessing predictive performance",
                  .locations = cells_stub()) |>
  fmt_percent(rows = 3:9, decimals = 0) |>
  fmt_integer(rows = 1) |>
  tab_stub_indent(
    rows = 3:9,
    indent = 3
  ) |>
  tab_style(
    locations = cells_row_groups(),
    style = cell_text(style = "italic")
  ) |>
  tab_style(
    locations = cells_column_labels(),
    style = list(cell_fill(color = "aquamarine4"),
                 cell_text(color = "white"))
  ) |>
  tab_style(
    locations = cells_body(columns = "All models"),
    style = cell_text(style = "italic")
  ) |>
  as_raw_html()
```

Those Bayesian models which did perform model selection took various approaches, with largely idiosyncratic methods across these studies. While direct comparison of model fit was rare amongst Bayesian methods, it is feasible ‚Äì @urban2023 identified the best model from a Bayesian candidate set using the predictive performance on both in and out-of-sample validation data. Another approach used by @cook2022 fit a global model including all covariates, before removing each covariate where the 95% credible interval of the posterior distribution overlapped zero and refitting the reduced model. @ahumada2013 took a hybrid approach, where model selection was conducted by a sequential method fitting models by MLE before refitting the best structure as a Bayesian model. Finally, @brown2014 capitalised on the advantages of the Bayesian framework and used reversible jump MCMC routines to perform model selection during model fitting.

Regardless of the implementation, assessment of model fit and model performance was rare amongst the articles in our sample. Only 18% of studies tested for goodness-of-fit, and just 7% calculated predictive performance with either in-sample or out-of-sample validation.

### Temporal trends in applications of DOMs 

While our temporally stratified sample allows us to consider changes in how DOMs have been applied over the past two decades, modest sample sizes within strata necessitate caution in interpretating these results. Nonetheless, there are several clear trends we believe are worth noting (Figure 6). Firstly, recent strata saw changes in the number of sites modelled in each study. In our two most recent strata spanning 2016-2023, the range in the number of sites was noticeably wide. While models continue to be fit with small numbers of sites, the upper quartile contained more sites than in previous strata (@fig-timeSeries A). The median number of covariates considered per parameter has also continually increased since the early years of DOMs, from 1.75 covariates in 2004-2007 to 4.75 in the 2020-2023 stratum (@fig-timeSeries B).

![Key trends in applications of dynamic occupancy models over the study period. a) The number of sites modelled in each dataset, presented on the log scale. b) The number of covariates considered per model parameter in each modelling workflow, presented on the log scale. c) The percentage of models in each stratum fit in the maximum likelihood or Bayesian frameworks. d) The percentage of articles in each stratum that used each of four non-exclusive covariate selection strategies. This panel includes only articles which fit models via maximum likelihood. e) The percentage of articles in each stratum that reported goodness-of-fit testing and model validation (with either in or out of sample data).](Figures/6_TimeSeries.png){#fig-timeSeries}

While Bayesian models were included in all strata of our sample, there was a marked increase in their frequency in the most recent stratum (Figure 6 C). This may in part be explained by the publication of accessible resources such as @k√©ry2021, which includes chapters on fitting DOMs in JAGS with associated code. Within the MLE implementations, the most popular model selection methods have shifted over time. The number of studies using predefined sets of candidate models has gradually declined, contemporaneous with an increase in articles using sequential model selection methods (@fig-timeSeries D). While there is evidence of improvement from earlier strata, goodness-of-fit testing and model validation using either in- or out-of-sample data remained uncommon even in more recent strata where tests were readily available in common R packages (@fig-timeSeries E).

# Discussion

Over the past two decades dynamic occupancy models have been applied to an increasingly broad range of objectives and research contexts. As their popularity has grown and new tools have become available, authors have implemented DOMs with wide ranging amounts of data, at small and large spatial and temporal scales, using diverse data collection techniques. While each of these studies share the same underlying methodology, their approaches to implementation and interpretation vary considerably. The approach to building any type of model will necessarily depend on the character of the data available and on the priorities of the model-builder. This precludes any prescription of the ‚Äòbest‚Äô way to build DOMs; however, we believe that there are several areas of the modelling process that merit closer consideration by both those using and further developing these methods.

### Defining occupancy and detection

Building and interpreting DOMs requires a firm understanding of what probabilities of occupancy and detection conceptually represent for a given dataset. However, arriving at appropriate definitions for these terms can be a challenge. What site occupancy describes is dependent on a variety of factors, including the spatial extent of sites, the duration of primary occasions, the survey methods used, and the ways that each of these relate to the life history traits of the target species [@valente2024]. Applications of DOMs in our review used data that varied across each of these axes, resulting in vastly different conceptions of occupancy and detection.

The appropriate definition of occupancy is closely related to the spatial extent of each site, relative to a species‚Äô home range within a primary occasion [@fig-occupancyVariants]. This relationship determines whether the closure assumption ‚Äì which states that the occupancy status of sites does not change within primary occasions such that the species is always available for detection at occupied sites ‚Äì is fulfilled. If this is the case, and assuming that the survey method can detect the species even if it occurs in only a portion of the site, occupancy simply represents the probability that the species is present within a site during a primary occasion. Conversely, if the home range of species is not wholly contained within a site, occupancy must be interpreted as the probability that a site is *used* by the species for at least some portion of the primary occasion (@fig-occupancyVariants bii-iii).

![An overview of how the size of a site relative to the focal species‚Äô home range during a primary occasion can result in differing definitions of site occupancy. In (a), where a site represents a discrete habitat patch, occupancy typically represents whether a site is occupied during a primary occasion. If each site corresponds with an individual‚Äôs home range (a-i), as can occur with nest box surveys, occupancy is equivalent to abundance. If each site can contain multiple home ranges (a-ii) as with surveys of water bodies, this occupancy-abundance relationship is lost. In (b), where sites are defined in continuous habitat, occupancy definitions are more variable. If sites are larger than the focal species home range (b-i), occupancy will still represent whether a site is occupied ‚Äì however, occupancy will not relate to abundance. Closure violations occur when individuals do not remain within a site for the full primary occasion (b-ii, b-iii). Here, occupancy represents whether a site is used during a primary occasion. If sites have a similar size to the species home range and home ranges do not overlap (b-ii), occupancy may retain some relationship with abundance. If sites are smaller than the home range (b-iii) as typically occurs with camera traps, the occupancy-abundance relationship is lost.](Figures/7_OccupancyVariation.png){#fig-occupancyVariants}

The relationship between sites and home ranges also determines whether occupancy corresponds with abundance [@steenweg2018]. In cases where each site corresponds with the home range of a single individual or pair, site occupancy may be fully equivalent to abundance. For example, this may be the case with many studies of spotted owls *(Strix occidentalis),* where sites typically include all possible owl territories in a region [@olson2005]. Alternatively, where sites are larger than home ranges, occupancy will only approach abundance at low densities. Users of DOMs should be conservative when making inference on abundance, noting that it typically requires making strong assumptions beyond those required for estimating occupancy or site use.

Earlier occupancy model research was often focused on conventional definitions of occupancy which require compliance with the closure assumption. This work emphasised how violations of this assumption can bias estimates of model parameters, leading to overestimates of occupancy when sites are not consistently occupied within primary occasions due to non-random mortality or movement of individuals [@otto2013; @valente2017]. These authors provide guidance for study designs to ensure closure, as well as tests and analysis-based solutions for cases where closure is violated [@rota2009; @kendall2013; @mackenzie2017].

More recently, authors have begun to consider closure violations less as a source of bias and more as a modifier to the definition of occupancy [@efford2012; @valente2024; @goldstein2024]. When movement of individuals during primary occasions results in closure violations such that a species is only available for detection during a subset of sampling occasions, occupancy represents something more akin to site use: the probability that a species is present at a site *at some point* during a primary occasion. Many DOMs in our review would best fit this definition of occupancy: closure is often an unreliable assumption when modelling the mobile birds and mammals which dominate our sample, particularly when sites do not align with species home ranges. When data is collected with autonomous units like camera traps or acoustic monitors, small detection ranges make violation of closure very likely, necessitating a definition of occupancy which represents the probability that a species uses habitat that overlaps with the unit‚Äôs detection range during the primary occasion [@wood2022].

Alternative definitions of occupancy have knock-on effects for detection probabilities with important implications for model building and interpretation. ‚ÄòDetection‚Äô is often described as the probability that a species is observed during a survey given that a site is occupied, depending largely on the ability of the observer to identify the species. However, in practice detection probabilities can include several other components ‚Äì individual movement patterns can determine whether a species is even available for detection at occupied sites, behaviour alters the perceptibility of a species, and variation in abundance changes the number of individuals available for detection [@guillera-arroita2017a]. Consider a study using acoustic monitors, where a species is considered detected if a call is identified within a one-day secondary occasion: the probability of detection would be contingent on the number of individuals in the area, whether any of them entered the recording range, whether they made any vocalisations, and whether human listeners or classifier software successfully identified the call. In this circumstance, detection would contain both ecological and observational components.

An unusual challenge arises when users seek to fit to DOMs to detection/non-detection data that is continuously recorded ‚Äì this may occur with camera traps or acoustic monitors which can run for long time periods, or with data from citizen science portals that lacks clearly delineated survey periods. In these situations, modellers must arbitrarily determine how to stratify detections into primary and secondary occasions (but note the availability of continuous detection models for secondary ‚Äúoccasions‚Äù; [@guillera-arroita2011; @emmet2021; @pautrel2024]. This stratification affects the temporal scale at which occupancy is measured, with corresponding changes to the definitions of occupancy and detection. The appropriate duration of these occasions will of course depend on research objectives and the ecology of the target species [@chave2013], but guidelines for approaching this task in DOMs specifically would hold value for the increasing numbers of authors fitting models to this type of data.

In all cases we echo recommendations made to users of occupancy-detection models more broadly, that they establish clear definitions for both occupancy and detection that correspond to the target species‚Äô biology and the structure of the data used for modelling [@goldstein2024]. While this is a productive exercise for clarifying internal assumptions and guiding choice of covariates, including these definitions in published articles also provides transparency and supports interpretation for readers less familiar with the study system.

### Identifying covariates for each modelled parameter

The definitions of occupancy and detection should strongly inform decisions on the covariates that are considered for inclusion in DOMs. Hypothesised relationships between occupancy dynamics and the environment should correspond with the spatial and temporal scale at which the data was collected, noting that the underlying mechanisms that drive occupancy at different timescales are likely to differ for many species.

Our review found that many studies did not include any covariates on initial occupancy. However, unless a study is conducted at very small extents or study sites are truly uniform in their initial suitability, one would expect some amount of non-random variation in occupancy probability across any study system. As seen in our review, many DOMs are applied at large spatial scales across significant habitat gradients. Omission of the factors that drive occupancy biases spatial predictions in static SDMs [@barry2006], which the initial occupancy component of DOMs conceptually resembles. In tests of predictions using DOMs, @briscoe2021 posit that poor spatial predictive performance may have been the result of a constrained covariate pool for parameters including initial occupancy. Where spatial predictions are of interest, it is prudent for users of DOMs to consider sufficient covariates to capture the key drivers of occupancy in the first primary occasion ‚Äì this may be less of a concern in cases where estimating trends in occupancy probability is a greater priority.

When choosing covariates for colonisation and extinction users should prioritise the factors most likely to be of importance in driving change *between* primary occasions. DOMs are generally first-order Markov models where occupancy probabilities are linked only to the preceding primary occasions; therefore, covariates should have some link to possible mechanisms of transition at this timescale. Interestingly, fewer than 50% of environmental covariates considered for transition probabilities in our review were time-varying. While some static covariates provide useful information on habitat suitability in general, dynamic covariates are increasingly available and can provide more nuance on how species respond to fluctuations in environmental conditions.

As previously mentioned, different definitions of detection probability can include aspects of species abundance, behaviour, and resource use which should be reflected in the choice of covariates considered for inclusion on this parameter. Most DOMs included in our review considered comparatively few (median = 3) covariates on detection, either environmental or structural. We encourage authors to consider fully how environmental factors might influence detection in their study system, and to avoid restricting these covariates to the occupancy dynamics parameters. Existing work on unmodelled heterogeneity in detection demonstrates a deleterious effect on estimates of occupancy probability in both SDMs and DOMs, highlighting the need for greater emphasis on this component of the model [@mcclintock2010; @lahoz-monfort2014].

The consequences of unmodelled heterogeneity on model outputs generally remains an understudied aspect of DOMs, despite ongoing acknowledgements that this is an area meriting further research [@mackenzie2006; @mackenzie2017]. Simulation studies exploring these scenarios would help to inform where this may be of concern and guide future research on model building practices. This includes explorations on how missing covariates on detection may influence estimates of other parameters in DOMs, particularly in cases where closure is violated and detection contains a large environmental component.

### Complexity in DOMs

One aspect of fitting DOMs meriting broader discussion centres on ‚Äòmodel complexity,‚Äô and how much must be incorporated into models to reliably estimate species occupancy under different contexts and use cases. Complexity is a broad term encompassing many aspects of a model, including the number of covariates included, the form of their relationship to response variables, and the overall structure of the model [@merow2014]. Opinions on simplicity versus complexity in ecological models are diverse - where some advocate for the simplest possible models, arguing that they are most generalisable; others insist that overly simple models cannot adequately represent the most important drivers in a system [@evans2013; @lonergan2014]. By their nature, DOMs are somewhat more complex than simpler models for studying occupancy due to their hierarchical structure, which is necessary to control for detectability and to capture occupancy dynamics. Within this structure, however, further complexity is up to the modeller: one can choose how many covariates to consider for inclusion on parameters, and how to represent the nature of the relationship between those covariates and parameters. In the applications of DOMs in our review, average complexity was somewhat low along both of these axes ‚Äì relatively few covariates per parameter were considered for inclusion, and the majority of studies did not consider non-linear responses nor interactions between covariates.

Research from correlative species distribution models (SDMs) indicates that allowing for more complex relationships can improve model performance in spatial predictions of occupancy [@valavi2023], an increasingly popular use-case for DOMs. Many common approaches for SDMs, such as MAXENT and Boosted Regression Trees, permit considerable flexibility in the shape of their covariate response curves and use of interactions, where supported by the data [@elith2008; @merow2013]. Within DOMs, there are promising developments in methods for incorporating additional complexity, including @joseph2020 ‚Äôs novel neural-network occupancy model which allows for exponentially higher levels of complexity, potentially offering improved performance for prediction-oriented studies. While no studies in our samples used these approaches, other means for flexible response shapes such as splines, BRTs, or machine learning based methods may offer other avenues for increased flexibility [@hutchinson2011; @rushing2019; @joseph2020]. Further research on these methods may provide new options where spatial predictive performance is a priority.

The emphasis on more complex responses in SDMs may also be attributed to their frequent application across relatively large geographic extents which might encompass the full species niche, where environmental relationships may be expected to be non-linear. However, we found that many DOMs were also implemented across large spatial extents where non-linear responses might be expected. When this is probable, modellers should ensure that covariate responses are ecologically realistic and appropriately reflect the hypothesised relationships [@austin2007]. Similar consideration should be given to interactions between covariates, given that these relationships are commonly expected based on ecological theory and that their exclusion can negatively impact model performance [@guisan2006]. This is not to suggest that modellers should consider arbitrary non-linear responses or covariate interactions that are not grounded in ecological theory, but that they should remain open to more complexity where merited by the data and study system. While overfitting models can be a concern, many covariate selection methods (including AIC-based approaches and Bayesian regularisation) will penalise excessive complexity and appropriate model evaluation (currently rare ‚Äì see below) can detect these issues.

### Covariate Selection

Methods used for covariate selection were particularly varied in reviewed DOMs, with a wide range of approaches used in both MLE and Bayesian frameworks and little consensus on the best techniques. Covariate selection is a particularly challenging task for DOMs relative to other common models for occupancy estimation, as testing alternative covariates across multiple parameters can result in a rapidly expanding pool of candidate models. Consider that while testing all combinations of 6 covariates for a simple correlative SDM would require fitting just 64 models, possible combinations of 6 covariates on each of the DOMs four parameters would require 24 million models, making exhaustive comparison computationally infeasible. Limited research has been conducted on the advantages of different methods for covariate selection in DOMs, and there is unlikely to be a one-size-fits-all approach which will be appropriate for all possible objectives. However, it is important to consider the implications of the different model selection approaches in common usage and their suitability for various use-cases.

The few papers that have addressed covariate selection in occupancy models have largely focused on AIC-based methods, which aim to identify models that are useful for prediction by selecting for fit while penalising complexity [@chakrabarti2011]. In a comparison of static occupancy models fit with three AIC-based approaches using simulated data, @doherty2012 found that while each method achieved similar predictive performance, estimates of covariate weights varied. They advise model averaging to mitigate this effect, but acknowledge that this effect is likely to be even larger in more complex models such as DOMs. More recent work by @morin2020 using occupancy models fit to field data had similar findings, with sequential model selection approaches often failing to identify the lowest AIC model amongst exhaustive combinations. They recommend that modellers carry more candidate models through each stage in sequential selection processes to increase the probability that the top models are identified, given that exhaustive model selection may not be feasible for DOMs with moderate-large numbers of potential covariates.

The most common application of DOMs was to test hypothesised relationships. In recent years, work from the causal modelling community has critiqued aspects of model selection in cases where the principal research objective is to test pre-defined environmental relationships [@tredennick2021]. @stewart2023 discuss this in the context of occupancy modelling, demonstrating the risks posed by certain ‚Äòcollider‚Äô variables which have causal relationships with both occupancy and other covariates in the candidate set. Where these colliders are present, the top models selected by AIC may produce inaccurate estimates of focal covariates, even where they produce more accurate estimates of occupancy probabilities. As a result of these concerns, recent work has reinforced suggestions to limit or avoid covariate selection when inference on hypothesised relationships is the primary objective [@tredennick2021; @arif2022; @popovic2024; @bolker2024]. These authors instead suggest a focus on more constrained model sets defined *a priori*, with careful consideration of the structural relationships between candidate covariates using tools such as directed acyclic graphs to clarify assumptions [@arif2023]. These firmer views on causal inference are not universal, and authors including @nichols2024 have defended the use of predictive models (including DOMs) coupled with thoughtful and constrained model selection as useful tools for inference, while noting the importance of carefully considering relationships among covariates.

Where inference on pre-specified hypotheses is not required, approaches to model selection may be more flexible. AIC-based model selection starting from a larger pool of candidate covariates is suitable for exploratory research, where the risk of bias in coefficient estimates and spurious correlations may be less of a concern [@tredennick2021]. Prediction remains somewhat underexplored for DOMs, and further research is needed on the best techniques for fitting models for this purpose [@briscoe2021]. While we discuss model evaluation in greater detail later in the discussion, model selection by cross-validation is a promising avenue where computationally feasible and is available via the R packages *ubms* and *unmarked* [@yates2023; @kellner2022; @kellner2023]*.*

Regardless of objective, Bayesian model selection for DOMs remains somewhat underexplored. @hooten2015 ‚Äôs guide to Bayesian model selection in ecology remains a valuable resource for possible methods for fitting and evaluating these models, and a range of promising methods including regularisation priors and reversible-jump MCMC merit future research on their suitability for use with DOMs [@park2008]. In one of the few comparative studies on model selection for Bayesian occupancy models, @stevens2019 found that models selected using the logarithmic scoring rule rather than WAIC or DIC produced better performing models for prediction. As the accessibility and popularity of Bayesian DOMs appears likely to continue to increase, further research and tool development in this space is necessary.

### Model assessment

Regardless of covariate selection protocol, it is important to determine whether a chosen model appropriately reflects the data and is suitable for its use case. However, current applications of DOMs report model assessment at rates lower than either single-season occupancy models or SDMs [@goldstein2024; @ara√∫jo2019]. This is perhaps because model assessment methods and guidance remain underdeveloped for DOMs: few goodness-of-fit tests have been proposed, and those which do exist require more empirical assessment for greater acceptance. Currently, @mackenzie2004 ‚Äôs approach for single-season occupancy models using a parametric bootstrap has been extended to DOMs and is implemented in the *AICcModAvg* and *unmarked* R packages ‚Äì @k√©ry2021 describe the test and present an alternative based on separately assessing fit to static and dynamic components of the model. In Bayesian implementations, posterior predictive checks offer means to assess model fit [@gelman2014]. @broms2016 discusses various options for model assessment in Bayesian single-season multi-species occupancy models, with insights that may also be applicable to DOMs. While further tests and developments of these methods are necessary to solidify their use, current authors should to the best extent possible continue to conduct and report goodness-of-fit tests using existing tools regardless of their research objective.

Studies interested in making spatial or temporal predictions require more substantial forms of model evaluation to quantify predictive performance [@ara√∫jo2005; @guisan2005]. As with other hierarchical models, model evaluation for DOMs can be difficult and somewhat uncertain compared to other model types, as the primary response variable of interest (species occupancy) is a latent variable where the true state is generally not known. Predictive performance evaluation is thus typically based on *observed* occupancy data, where a DOM is used to compute the probability of observing the species and this is compared with the field data. This method confounds the occupancy and detection processes, restricting our ability to determine whether any variation is correctly apportioned to each of these processes.

While predictive performance should ideally be tested with independent datasets, this is generally not practicable with DOMs. Best practice should involve setting aside a portion of data for testing final models, where this is not possible, cross-validation should be considered to attain an estimate of performance. Validation of DOM predictions can be done by splitting datasets temporally and using latter years for evaluation or by setting aside sites [@briscoe2021]. Site-based cross validation is included in several packages including *unmarked* and *ubms* [@kellner2022; @kellner2023].

+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Topic                              | Recommendations                                                                                                                                                                                                             | Priorities                                                                                                                          |
+====================================+=============================================================================================================================================================================================================================+=====================================================================================================================================+
| Defining occupancy and detection   | -   Explicitly state context-dependent definitions of occupancy and detection probabilities.                                                                                                                                | -   Develop guidelines for delineating primary occasions in continuous data.                                                        |
+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Covariates for model parameters    | -   Choose relevant covariates for colonization and extinction, aligned with the temporal scale of changes in occupancy.                                                                                                    | -   Assess how missing drivers of heterogeneity on one parameter affect estimates of the other parameters and model predictions.    |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   Ensure that key drivers are also considered for initial occupancy, particularly when making spatial predictions.                                                                                                        |                                                                                                                                     |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   Ensure that environmental aspects of detection are reflected in candidate covariates.                                                                                                                                   |                                                                                                                                     |
+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Complexity and covariate responses | -   Align covariate responses with hypothesised relationships, testing non-linear responses or interactions where appropriate.                                                                                              | -   Explore the best ways to include greater complexity in covariate responses, such as splines and machine learning based methods. |
|                                    |                                                                                                                                                                                                                             | -   Assess influence of covariate quantity and response complexity on predictive performance and uncertainty.                       |
+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Model selection                    | -   For all objectives, ensure reported methods are comprehensive.                                                                                                                                                          | -   Identify best approaches to model selection for various objectives while limiting computational costs.                          |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   When testing hypotheses, include clear rationale for covariate inclusions, such as by creating directed acyclic graphs. Some authors recommend constraining candidate sets or avoiding covariate selection altogether.  | -   Compare performance of emerging Bayesian methods for model selection.                                                           |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   Consider all models with similar support.                                                                                                                                                                               |                                                                                                                                     |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   Be aware that results of model selection are sensitive to implementation. When using sequential selection, test more models at each stage to avoid missing the best-performing model.                                   |                                                                                                                                     |
+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Model assessment                   | -   Available goodness-of-fit tests should always be conducted and reported.                                                                                                                                                | -   Existing goodness-of-fit tests should be further validated to ease concerns regarding their use.                                |
|                                    |                                                                                                                                                                                                                             |                                                                                                                                     |
|                                    | -   Data should be reserved for out-of-sample validation wherever possible, and especially when prediction is an objective. If not feasible, in-sample validation should be performed and performance metrics reported.     | -   Additional research on methods for performance evaluation in hierarchical models is necessary                                   |
+------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+

: A summary of recommendations for current users of DOMs and priorities for further research.

# Conclusions

In the two decades since the publication of @mackenzie2003, use of dynamic occupancy models has increased and they have been applied to a broad range of data types and ecological and applied problems. This expansion can pose challenges in navigating the model building processes and aligning data, model and interpretations to produce useful outputs. Many of our recommendations thus simply implore users to take stock at key points to clarify their assumptions and expectations. With frequent use of DOMs for important problems such as managing critically endangered species, guiding public health decisions and tracking harmful invasive species, understanding the sensitivity of model outputs to decisions made in the model fitting process becomes increasingly important. Major uncertainties remain in key areas of the model development process including model selection and evaluation, with much of the existing guidance based on the static occupancy modelling literature [@mackenzie2017]. Several of the research priorities we identified relate to increasingly common use-cases ‚Äì such as generating spatial and temporal predictions, and modelling data derived from novel detection techniques. Targeted research and guidance specific to DOMs will be needed to ensure that the potential of these tools can be realised, and they can reliably inform conservation and management decisions.
